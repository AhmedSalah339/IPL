{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openpyxl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install EvalML","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport evalml\nfrom evalml.automl import AutoMLSearch\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:40:13.967987Z","iopub.execute_input":"2021-07-23T13:40:13.968589Z","iopub.status.idle":"2021-07-23T13:40:13.982654Z","shell.execute_reply.started":"2021-07-23T13:40:13.968541Z","shell.execute_reply":"2021-07-23T13:40:13.981878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the data","metadata":{}},{"cell_type":"code","source":"base = '/kaggle/input/ipl-data-set/'\nnames = ['matches.csv','teamwise_home_and_away.csv','deliveries.csv','most_runs_average_strikerate.csv','teams.csv']\nfor i,name in enumerate(names):\n    my_code = name[:-4]+'='+'pd.read_csv(\"'+base+name+'\")'\n    exec(my_code)\n\nplayers = pd.read_excel(base+'Players.xlsx')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:54:12.241976Z","iopub.execute_input":"2021-07-23T14:54:12.242507Z","iopub.status.idle":"2021-07-23T14:54:12.690657Z","shell.execute_reply.started":"2021-07-23T14:54:12.242458Z","shell.execute_reply":"2021-07-23T14:54:12.689637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's use AutoML to design initial base model fast","metadata":{}},{"cell_type":"code","source":"matches['date'] = pd.to_datetime(matches['date'])\nmatches = matches.set_index('date')\nmatches.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:54:15.577958Z","iopub.execute_input":"2021-07-23T14:54:15.578362Z","iopub.status.idle":"2021-07-23T14:54:15.60462Z","shell.execute_reply.started":"2021-07-23T14:54:15.57833Z","shell.execute_reply":"2021-07-23T14:54:15.603414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A lot of the features here are info about after the match which are to be discarded to avoid data leackage","metadata":{}},{"cell_type":"code","source":"matches","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:55:12.362971Z","iopub.execute_input":"2021-07-23T14:55:12.363405Z","iopub.status.idle":"2021-07-23T14:55:12.395096Z","shell.execute_reply.started":"2021-07-23T14:55:12.36337Z","shell.execute_reply":"2021-07-23T14:55:12.393967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matches_auto = matches.copy()\nmatches_auto['winner_binary'] = matches_auto.apply(lambda x:1 if x[3] == x[9]else 0,axis=1)\nmatches_auto = matches_auto.drop('winner',axis=1)\nmatches_auto = matches_auto.drop(['id','umpire1','umpire2','umpire3','toss_winner','toss_decision','result','dl_applied','win_by_runs','win_by_wickets','player_of_match','venue'],axis=1)\nmatches_auto = matches_auto.astype(\"category\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:55:36.966265Z","iopub.execute_input":"2021-07-23T14:55:36.966658Z","iopub.status.idle":"2021-07-23T14:55:36.999793Z","shell.execute_reply.started":"2021-07-23T14:55:36.966625Z","shell.execute_reply":"2021-07-23T14:55:36.998823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We will predict for the 2019 season","metadata":{}},{"cell_type":"code","source":"X = matches_auto.drop('winner_binary',axis=1)\ny = matches_auto['winner_binary']\nX_train = X[X.index<='2018-12-30']\nX_test = X[X.index>'2018-12-30']\ny_train = y[y.index<='2018-12-30']\ny_test = y[y.index>'2018-12-30']\n# X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='time series binary')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:55:38.947976Z","iopub.execute_input":"2021-07-23T14:55:38.948401Z","iopub.status.idle":"2021-07-23T14:55:38.959041Z","shell.execute_reply.started":"2021-07-23T14:55:38.948365Z","shell.execute_reply":"2021-07-23T14:55:38.957698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"automl = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')\nautoml.search()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:55:50.440246Z","iopub.execute_input":"2021-07-23T14:55:50.440653Z","iopub.status.idle":"2021-07-23T14:56:10.08034Z","shell.execute_reply.started":"2021-07-23T14:55:50.440613Z","shell.execute_reply":"2021-07-23T14:56:10.079174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The best 3 models are very close and none is making a good job in the problem (due to low information of course, but we will compare our models to this base model","metadata":{}},{"cell_type":"code","source":"log_loss(true_binary,list(exp.values))","metadata":{"execution":{"iopub.status.busy":"2021-07-23T15:03:01.28111Z","iopub.execute_input":"2021-07-23T15:03:01.281529Z","iopub.status.idle":"2021-07-23T15:03:01.291327Z","shell.execute_reply.started":"2021-07-23T15:03:01.281495Z","shell.execute_reply":"2021-07-23T15:03:01.290256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's try another base model which will guess the winner based on who won more matches in the past ","metadata":{}},{"cell_type":"code","source":"matches_train = matches[matches.index<='2018-12-30']\nmatches_test = matches[matches.index>'2018-12-30']\nw = matches_train.groupby('winner').count()['team1']\ntrue_binary = []\nexpexted_binary = []\nfor i,row in matches_test.iterrows():\n    t1_wins = 0\n    t2_wins = 0\n    t1 = row['team1']\n    t2 = row['team2']\n    winner = row['winner']\n    if t1 in w:\n        t1_wins = w[t1]\n    if t2 in w:    \n        t2_wins = w[t2]\n    expected_winner = 0 if t1_wins > t2_wins else 1\n    true_winner = 0 if t1==winner  else 1\n    expexted_binary.append(expected_winner)\n    true_binary.append(true_winner )\n\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:47:30.128996Z","iopub.execute_input":"2021-07-23T14:47:30.129438Z","iopub.status.idle":"2021-07-23T14:47:30.151837Z","shell.execute_reply.started":"2021-07-23T14:47:30.129406Z","shell.execute_reply":"2021-07-23T14:47:30.150781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nbest_pipeline = automl.best_pipeline\nexp = best_pipeline.predict(X_test)\nlog_loss(exp,true_binary)/len(exp)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T15:04:48.025087Z","iopub.execute_input":"2021-07-23T15:04:48.025479Z","iopub.status.idle":"2021-07-23T15:04:48.236473Z","shell.execute_reply.started":"2021-07-23T15:04:48.025448Z","shell.execute_reply":"2021-07-23T15:04:48.235467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_loss(expexted_binary,true_binary)/len(true_binary)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T15:04:49.094467Z","iopub.execute_input":"2021-07-23T15:04:49.094849Z","iopub.status.idle":"2021-07-23T15:04:49.104215Z","shell.execute_reply.started":"2021-07-23T15:04:49.094819Z","shell.execute_reply":"2021-07-23T15:04:49.10324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> by taking the mean log of the hard decision for both models there is no significant difference between them, so we can use any as a base line","metadata":{}}]}